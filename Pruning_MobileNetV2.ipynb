{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "o0_qvnJZrt-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd15764a-8c5e-42a4-ff24-be18fcffd8db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "# Load the default MobileNetV2 model\n",
        "mobilenet_v2 = models.mobilenet_v2(pretrained=False, num_classes=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use Torch-Pruning [1] library to help us with the pruning.\n",
        "\n",
        "**[1]** Fang, Gongfan, et al. \"Depgraph: Towards any structural pruning.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2023): 16091â€“16101.\n",
        "\n",
        "[link text](https://github.com/VainF/Torch-Pruning)\n"
      ],
      "metadata": {
        "id": "0kp8ZpZDkD0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install torch-pruning: we will use it to apply structured pruning on our model\n",
        "!pip install -q torch-pruning"
      ],
      "metadata": {
        "id": "Roqxbh-BvXPg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_pruning as tp"
      ],
      "metadata": {
        "id": "QOOGbSH8ir1n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_blocks(model):\n",
        "    \"\"\"\n",
        "    Extracts and organizes the main blocks of a mobilenet_v2 model while\n",
        "    identifying blocks that should be ignored during pruning.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model from which blocks will be extracted.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - model_blocks (list): A list of extracted model blocks, excluding the first block.\n",
        "            - ignored_blocks (list): A list containing the classifier and the first block, which are to be ignored during pruning.\n",
        "\n",
        "    Description:\n",
        "        - Iterates through the top-level children of the model.\n",
        "        - If a module is named 'classifier', it is added to the ignored blocks.\n",
        "        - If a module is named 'features', its submodules are extracted.\n",
        "        - The first submodule of 'features' is added to the ignored blocks, while the remaining submodules\n",
        "          are considered as the main model blocks.\n",
        "    \"\"\"\n",
        "\n",
        "    blocks = []\n",
        "    model_blocks = []\n",
        "    ignored_blocks = []\n",
        "\n",
        "    # Iterate through the top-level children of the model\n",
        "    for name, module in model.named_children():\n",
        "        if name == 'classifier':\n",
        "            ignored_blocks.append(module)\n",
        "\n",
        "        elif name == 'features':\n",
        "            blocks += module  # Assuming 'features' is an iterable of blocks\n",
        "\n",
        "    model_blocks.extend(blocks[1:])  # Exclude the first block\n",
        "    ignored_blocks.append(blocks[0])  # Ignore the first block\n",
        "\n",
        "    return model_blocks, ignored_blocks\n"
      ],
      "metadata": {
        "id": "yTDutgzGzjsf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare dummy input and output to perform forward and backward passes\n",
        "input = torch.randn(1, 3, 80, 80)\n",
        "output = torch.tensor([0])"
      ],
      "metadata": {
        "id": "zevSBPbQG6Q8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def selective_block_pruning(original_model, prune_method, pruning_ratios, input_sample, output_sample, device):\n",
        "    \"\"\"\n",
        "    Performs selective block-wise pruning on a given model based on specified pruning ratios.\n",
        "\n",
        "    Args:\n",
        "        original_model (torch.nn.Module): The trained model to be pruned.\n",
        "        prune_method (str): The pruning method to use. Supports 'channel_pruning_Taylor_importance'.\n",
        "        pruning_ratios (list of float): A list containing pruning ratios for each model block.\n",
        "        input_sample (torch.Tensor): A sample input tensor for computing importance scores.\n",
        "        output_sample (torch.Tensor): The corresponding output tensor for computing loss.\n",
        "        device (torch.device): The device (CPU/GPU) on which to perform pruning.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - pruned_model (torch.nn.Module): The pruned model.\n",
        "            - macs (int): The number of MAC operations after pruning.\n",
        "            - nparams (int): The number of parameters after pruning.\n",
        "\n",
        "    Description:\n",
        "        - Creates a deep copy of the model to avoid modifying the original.\n",
        "        - Extracts model blocks and identifies blocks to ignore.\n",
        "        - Initializes pruning importance using Taylor importance scoring.\n",
        "        - Computes importance scores via forward and backward passes.\n",
        "        - Iterates through each block, applying pruning selectively.\n",
        "        - Adjusts the pruning ratio dynamically if no parameters are reduced.\n",
        "        - Frees memory after pruning to optimize GPU usage.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a copy of the model and move it to the specified device\n",
        "    model = copy.deepcopy(original_model).to(device)\n",
        "\n",
        "    # Extract model blocks and ignored blocks\n",
        "    model_blocks, ignored_blocks = get_blocks(model)\n",
        "\n",
        "    # Prepare pruning information for each block\n",
        "    pruning_info = {\n",
        "        i: {\"block\": model_blocks[i], \"pruning_ratio\": ratio}\n",
        "        for i, ratio in enumerate(pruning_ratios)\n",
        "    }\n",
        "\n",
        "    if prune_method == 'channel_pruning_Taylor_importance':\n",
        "        # Initialize Taylor importance for pruning\n",
        "        imp = tp.importance.TaylorImportance()\n",
        "\n",
        "        # Move input and output samples to the device\n",
        "        input_sample, output_sample = input_sample.to(device), output_sample.to(device)\n",
        "        loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Compute importance scores via forward and backward passes\n",
        "        if isinstance(imp, tp.importance.TaylorImportance):\n",
        "            preds = model(input_sample)\n",
        "            loss = loss_function(preds, output_sample)\n",
        "            loss.backward()\n",
        "\n",
        "        # Compute initial MACs and parameter count\n",
        "        original_macs, original_nparams = tp.utils.count_ops_and_params(model, input_sample)\n",
        "\n",
        "        # Iterate through each block and apply pruning\n",
        "        for i, info in pruning_info.items():\n",
        "            block_to_prune = info[\"block\"]\n",
        "            pruning_ratio = info[\"pruning_ratio\"]\n",
        "\n",
        "            if pruning_ratio == 0:\n",
        "                continue  # Skip pruning for blocks with a ratio of 0\n",
        "\n",
        "            # Ignore all blocks except the current block to be pruned\n",
        "            ignored_layers_block = [pruning_info[j][\"block\"] for j in range(len(pruning_info)) if j != i]\n",
        "            combined_ignored_layers = ignored_blocks + ignored_layers_block\n",
        "\n",
        "            count = 0  # Counter for consecutive iterations without parameter reduction\n",
        "\n",
        "            while True:\n",
        "                # Apply pruning to the current block\n",
        "                pruner_group = tp.pruner.MagnitudePruner(\n",
        "                    model,\n",
        "                    example_inputs=input_sample,\n",
        "                    importance=imp,\n",
        "                    pruning_ratio=pruning_ratio,\n",
        "                    ignored_layers=combined_ignored_layers\n",
        "                )\n",
        "                pruner_group.step()\n",
        "\n",
        "                # Recalculate MACs and parameters after pruning\n",
        "                macs, nparams = tp.utils.count_ops_and_params(model, input_sample)\n",
        "\n",
        "                # If no parameters were reduced, adjust the pruning ratio or terminate pruning\n",
        "                if original_nparams - nparams == 0:\n",
        "                    count += 1\n",
        "                    if count == 1:\n",
        "                        pruning_ratio = 0.5  # Adjust pruning ratio for better pruning effect\n",
        "                    else:\n",
        "                        break\n",
        "\n",
        "                # Update the pruning ratio and parameter count for iterative pruning\n",
        "                original_nparams = nparams\n",
        "\n",
        "        # Free up memory\n",
        "        del input_sample, output_sample, preds\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return model, macs, nparams"
      ],
      "metadata": {
        "id": "pozOYFELsEMv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity_analysis_with_contributions(original_model, device, input_sample, output_sample, criterion=None):\n",
        "    \"\"\"\n",
        "    Analyzes the impact of block-wise pruning on model performance and resource consumption.\n",
        "\n",
        "    Args:\n",
        "        original_model (torch.nn.Module): The neural network model to analyze.\n",
        "        device (torch.device): The device (CPU/GPU) for computations.\n",
        "        input_sample (torch.Tensor): A sample input tensor for inference and pruning evaluation.\n",
        "        output_sample (torch.Tensor): The expected output tensor for loss computation.\n",
        "        criterion (callable, optional): The loss function used for evaluation (default: None).\n",
        "\n",
        "    Returns:\n",
        "        list: A list of weighted importance scores for each block, representing their contribution to performance degradation.\n",
        "\n",
        "    Description:\n",
        "        - Extracts and organizes model blocks while identifying ignored blocks.\n",
        "        - Computes the baseline performance and initial MACs/parameter count.\n",
        "        - Iteratively prunes each block, measuring the resulting MACs and parameter reduction.\n",
        "        - Computes the relative contributions of each block to performance degradation and resource savings.\n",
        "        - Returns a weighted importance score for each block, based on its impact on parameter reduction and MACs.\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract model blocks and ignored blocks\n",
        "    model_blocks, ignored_blocks = get_blocks(original_model)\n",
        "    blocks_number = len(model_blocks)\n",
        "\n",
        "    params_reduction = []\n",
        "    macs_reduction = []\n",
        "\n",
        "    # Move the model to the specified device\n",
        "    original_model.to(device)\n",
        "\n",
        "    # Compute initial MACs and parameter count\n",
        "    original_macs, original_nparams = tp.utils.count_ops_and_params(original_model, input_sample)\n",
        "\n",
        "    # Iterate through each block and analyze pruning impact\n",
        "    for block_idx in range(blocks_number):\n",
        "        print(f\"Replacing block {block_idx}\")\n",
        "\n",
        "        # Generate pruning ratios, pruning only the current block\n",
        "        pruning_ratios = (np.eye(blocks_number) * 0.8)[block_idx]\n",
        "\n",
        "        # Apply block-wise pruning\n",
        "        pruned_model, macs, nparams = selective_block_pruning(\n",
        "            original_model, 'channel_pruning_Taylor_importance',\n",
        "            pruning_ratios, input_sample, output_sample, device\n",
        "        )\n",
        "\n",
        "        # Compute percentage reductions\n",
        "        params_reduction.append((original_nparams - nparams) / original_nparams * 100)\n",
        "        macs_reduction.append((original_macs - macs) / original_macs * 100)\n",
        "\n",
        "        print(f\"MACs reduction: {macs_reduction[-1]:.2f}% | Parameters reduction: {params_reduction[-1]:.2f}%\")\n",
        "\n",
        "        # Move the pruned model to the device for performance evaluation\n",
        "        pruned_model.to(device)\n",
        "\n",
        "    weighted_importance_scores = []\n",
        "    print(f\"\\nRelative contribution of each block to total MACs and parameter reductions:\")\n",
        "\n",
        "    # Compute weighted importance scores for each block\n",
        "    for block_idx in range(blocks_number):\n",
        "        relative_contribution_params = 100 - params_reduction[block_idx]\n",
        "        relative_contribution_macs = 100 - macs_reduction[block_idx]\n",
        "\n",
        "        # Weighted importance calculation (equal weighting between MACs and parameters)\n",
        "        weight_params = 0.5\n",
        "        weight_macs = 0.5\n",
        "        weighted_importance = (weight_params * relative_contribution_params) + (weight_macs * relative_contribution_macs)\n",
        "\n",
        "        print(f'Block {block_idx} reduces {macs_reduction[block_idx]:.2f}% of MACs and {params_reduction[block_idx]:.2f}% of parameters.')\n",
        "        print(f'Weighted importance score for Block {block_idx}: {weighted_importance:.2f}')\n",
        "\n",
        "        weighted_importance_scores.append(weighted_importance)\n",
        "\n",
        "    return weighted_importance_scores"
      ],
      "metadata": {
        "id": "hrK1OMG2wobs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "importance_scores = perplexity_analysis_with_contributions(mobilenet_v2, input_sample=input, output_sample=output, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8r9snkU5TAg",
        "outputId": "4c093eeb-a660-42ac-d05d-6018bc0bb831"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replacing block 0\n",
            "MACs reduction: 6.91% | Parameters reduction: 0.09%\n",
            "Replacing block 1\n",
            "MACs reduction: 9.42% | Parameters reduction: 0.23%\n",
            "Replacing block 2\n",
            "MACs reduction: 7.98% | Parameters reduction: 0.39%\n",
            "Replacing block 3\n",
            "MACs reduction: 4.81% | Parameters reduction: 0.44%\n",
            "Replacing block 4\n",
            "MACs reduction: 3.34% | Parameters reduction: 0.66%\n",
            "Replacing block 5\n",
            "MACs reduction: 3.34% | Parameters reduction: 0.66%\n",
            "Replacing block 6\n",
            "MACs reduction: 2.28% | Parameters reduction: 0.94%\n",
            "Replacing block 7\n",
            "MACs reduction: 3.03% | Parameters reduction: 2.43%\n",
            "Replacing block 8\n",
            "MACs reduction: 3.03% | Parameters reduction: 2.43%\n",
            "Replacing block 9\n",
            "MACs reduction: 3.03% | Parameters reduction: 2.43%\n",
            "Replacing block 10\n",
            "MACs reduction: 3.71% | Parameters reduction: 2.98%\n",
            "Replacing block 11\n",
            "MACs reduction: 6.59% | Parameters reduction: 5.29%\n",
            "Replacing block 12\n",
            "MACs reduction: 6.59% | Parameters reduction: 5.29%\n",
            "Replacing block 13\n",
            "MACs reduction: 5.12% | Parameters reduction: 6.95%\n",
            "Replacing block 14\n",
            "MACs reduction: 6.40% | Parameters reduction: 14.34%\n",
            "Replacing block 15\n",
            "MACs reduction: 6.40% | Parameters reduction: 14.34%\n",
            "Replacing block 16\n",
            "MACs reduction: 17.61% | Parameters reduction: 39.62%\n",
            "Replacing block 17\n",
            "MACs reduction: 8.24% | Parameters reduction: 18.61%\n",
            "\n",
            "Relative contribution of each block to total MACs and parameter reductions:\n",
            "Block 0 reduces 6.91% of MACs and 0.09% of parameters.\n",
            "Weighted importance score for Block 0: 96.50\n",
            "Block 1 reduces 9.42% of MACs and 0.23% of parameters.\n",
            "Weighted importance score for Block 1: 95.18\n",
            "Block 2 reduces 7.98% of MACs and 0.39% of parameters.\n",
            "Weighted importance score for Block 2: 95.82\n",
            "Block 3 reduces 4.81% of MACs and 0.44% of parameters.\n",
            "Weighted importance score for Block 3: 97.37\n",
            "Block 4 reduces 3.34% of MACs and 0.66% of parameters.\n",
            "Weighted importance score for Block 4: 98.00\n",
            "Block 5 reduces 3.34% of MACs and 0.66% of parameters.\n",
            "Weighted importance score for Block 5: 98.00\n",
            "Block 6 reduces 2.28% of MACs and 0.94% of parameters.\n",
            "Weighted importance score for Block 6: 98.39\n",
            "Block 7 reduces 3.03% of MACs and 2.43% of parameters.\n",
            "Weighted importance score for Block 7: 97.27\n",
            "Block 8 reduces 3.03% of MACs and 2.43% of parameters.\n",
            "Weighted importance score for Block 8: 97.27\n",
            "Block 9 reduces 3.03% of MACs and 2.43% of parameters.\n",
            "Weighted importance score for Block 9: 97.27\n",
            "Block 10 reduces 3.71% of MACs and 2.98% of parameters.\n",
            "Weighted importance score for Block 10: 96.66\n",
            "Block 11 reduces 6.59% of MACs and 5.29% of parameters.\n",
            "Weighted importance score for Block 11: 94.06\n",
            "Block 12 reduces 6.59% of MACs and 5.29% of parameters.\n",
            "Weighted importance score for Block 12: 94.06\n",
            "Block 13 reduces 5.12% of MACs and 6.95% of parameters.\n",
            "Weighted importance score for Block 13: 93.97\n",
            "Block 14 reduces 6.40% of MACs and 14.34% of parameters.\n",
            "Weighted importance score for Block 14: 89.63\n",
            "Block 15 reduces 6.40% of MACs and 14.34% of parameters.\n",
            "Weighted importance score for Block 15: 89.63\n",
            "Block 16 reduces 17.61% of MACs and 39.62% of parameters.\n",
            "Weighted importance score for Block 16: 71.39\n",
            "Block 17 reduces 8.24% of MACs and 18.61% of parameters.\n",
            "Weighted importance score for Block 17: 86.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importance_scores"
      ],
      "metadata": {
        "id": "lkmu9tK950q7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8fcf99b-5e32-4cc0-ad73-d519ebee6e69"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[96.50298358388602,\n",
              " 95.17637452857088,\n",
              " 95.81562958266878,\n",
              " 97.3726661323213,\n",
              " 97.99966389283736,\n",
              " 97.99966389283736,\n",
              " 98.39090232932065,\n",
              " 97.27176913797129,\n",
              " 97.27176913797129,\n",
              " 97.27176913797129,\n",
              " 96.65740645079322,\n",
              " 94.05939990621073,\n",
              " 94.05939990621073,\n",
              " 93.96611235251615,\n",
              " 89.62809233485658,\n",
              " 89.62809233485658,\n",
              " 71.38556084451452,\n",
              " 86.57574588715747]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_pruning_ratios(importance_scores, max_pruning_ratio=0.9, k=5):\n",
        "    \"\"\"\n",
        "    Calculate pruning ratios based on intense nonlinear scaling (exponential decay) of the relative contributions.\n",
        "\n",
        "    Parameters:\n",
        "    - importance_scores (list): List of importance scores (relative contributions in percentages) of each block.\n",
        "    - max_pruning_ratio (float): Maximum pruning ratio to be assigned to the least important layer. Default is 0.9.\n",
        "    - k (int): Factor controlling the intensity of the scaling (larger k makes the ratio more intense).\n",
        "\n",
        "    Returns:\n",
        "    - pruning_ratios (list): List of pruning ratios for each block.\n",
        "    \"\"\"\n",
        "    # Normalize the contributions to get values between 0 and 1\n",
        "    total_contribution = sum(importance_scores)\n",
        "    normalized_contributions = [contribution / total_contribution for contribution in importance_scores]\n",
        "\n",
        "    # Apply exponential decay to magnify the effect for less important blocks\n",
        "    pruning_factors = [np.exp(-k * nc) for nc in normalized_contributions]\n",
        "\n",
        "    # Normalize the pruning factors so they stay within the max pruning ratio\n",
        "    max_factor = max(pruning_factors)\n",
        "    normalized_factors = [pf / max_factor for pf in pruning_factors]\n",
        "\n",
        "    # Scale by the maximum pruning ratio\n",
        "    pruning_ratios = [max_pruning_ratio * nf for nf in normalized_factors]\n",
        "\n",
        "    pruning_ratios = [round(num, 2) for num in pruning_ratios]\n",
        "\n",
        "    return pruning_ratios"
      ],
      "metadata": {
        "id": "FtG9aX2E55v1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_pruning_ratio = 0.99 # Maximum pruning ratio (99%)\n",
        "k = 2 # Controls the intensity of the scaling\n",
        "\n",
        "pruning_ratios = calculate_pruning_ratios(importance_scores, max_pruning_ratio, k)\n",
        "\n",
        "# Print the pruning ratios for each block\n",
        "for i, ratio in enumerate(pruning_ratios):\n",
        "    print(f\"Block {i} Pruning Ratio: {ratio:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajizvd7I57-F",
        "outputId": "6a9bc62c-0716-4732-c211-38fd560ee285"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block 0 Pruning Ratio: 0.9600\n",
            "Block 1 Pruning Ratio: 0.9600\n",
            "Block 2 Pruning Ratio: 0.9600\n",
            "Block 3 Pruning Ratio: 0.9600\n",
            "Block 4 Pruning Ratio: 0.9600\n",
            "Block 5 Pruning Ratio: 0.9600\n",
            "Block 6 Pruning Ratio: 0.9600\n",
            "Block 7 Pruning Ratio: 0.9600\n",
            "Block 8 Pruning Ratio: 0.9600\n",
            "Block 9 Pruning Ratio: 0.9600\n",
            "Block 10 Pruning Ratio: 0.9600\n",
            "Block 11 Pruning Ratio: 0.9600\n",
            "Block 12 Pruning Ratio: 0.9600\n",
            "Block 13 Pruning Ratio: 0.9600\n",
            "Block 14 Pruning Ratio: 0.9700\n",
            "Block 15 Pruning Ratio: 0.9700\n",
            "Block 16 Pruning Ratio: 0.9900\n",
            "Block 17 Pruning Ratio: 0.9700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_model(original_model, prune_method, pruning_ratios, input_sample, output_sample, device):\n",
        "    \"\"\"\n",
        "    Prunes a neural network model block-wise using the specified pruning method.\n",
        "\n",
        "    Args:\n",
        "        original_model (torch.nn.Module): The trained model to be pruned.\n",
        "        prune_method (str): The pruning method to use. Currently supports 'channel_pruning_Taylor_importance'.\n",
        "        pruning_ratios (list of float): A list of pruning ratios corresponding to each model block.\n",
        "        input_sample (torch.Tensor): A sample input tensor for computing importance scores.\n",
        "        output_sample (torch.Tensor): The expected output tensor for loss computation.\n",
        "        device (torch.device): The device (CPU/GPU) on which pruning is performed.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - pruned_model (torch.nn.Module): The pruned model.\n",
        "            - macs (int): The number of MAC operations after pruning.\n",
        "            - nparams (int): The number of parameters after pruning.\n",
        "\n",
        "    Description:\n",
        "        - Creates a deep copy of the model to preserve the original.\n",
        "        - Extracts model blocks and identifies ignored blocks.\n",
        "        - Computes importance scores using Taylor importance for structured pruning.\n",
        "        - Iteratively prunes each block based on the specified pruning ratios.\n",
        "        - Updates MACs and parameter count after pruning.\n",
        "        - Frees memory after pruning to optimize GPU usage.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a copy of the model and move it to the specified device\n",
        "    model = copy.deepcopy(original_model).to(device)\n",
        "\n",
        "    # Extract model blocks and ignored blocks\n",
        "    model_blocks, ignored_blocks = get_blocks(model)\n",
        "\n",
        "    # Prepare pruning information for each block\n",
        "    pruning_info = {\n",
        "        i: {\"block\": model_blocks[i], \"pruning_ratio\": ratio}\n",
        "        for i, ratio in enumerate(pruning_ratios)\n",
        "    }\n",
        "\n",
        "    if prune_method == 'channel_pruning_Taylor_importance':\n",
        "        # Initialize Taylor importance for pruning\n",
        "        imp = tp.importance.TaylorImportance()\n",
        "\n",
        "        # Move input and output samples to the device\n",
        "        input_sample, output_sample = input_sample.to(device), output_sample.to(device)\n",
        "        loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Compute importance scores via forward and backward passes\n",
        "        preds = model(input_sample)\n",
        "        loss = loss_function(preds, output_sample)\n",
        "        loss.backward()\n",
        "\n",
        "        # Compute initial MACs and parameter count\n",
        "        original_macs, original_nparams = tp.utils.count_ops_and_params(model, input_sample)\n",
        "\n",
        "        # Iterate through each block and apply pruning\n",
        "        for i, info in pruning_info.items():\n",
        "            block_to_prune = info[\"block\"]\n",
        "            pruning_ratio = info[\"pruning_ratio\"]\n",
        "\n",
        "            # Ignore all blocks except the current block to be pruned\n",
        "            ignored_layers_block = [pruning_info[j][\"block\"] for j in range(len(pruning_info)) if j != i]\n",
        "            combined_ignored_layers = ignored_blocks + ignored_layers_block\n",
        "\n",
        "            print(f\"Pruning block {i} with initial ratio: {pruning_ratio}\")\n",
        "\n",
        "            # Apply pruning to the current block\n",
        "            pruner_group = tp.pruner.MagnitudePruner(\n",
        "                model,\n",
        "                example_inputs=input_sample,\n",
        "                importance=imp,\n",
        "                pruning_ratio=pruning_ratio,\n",
        "                ignored_layers=combined_ignored_layers\n",
        "            )\n",
        "            pruner_group.step()\n",
        "\n",
        "    # Recalculate MACs and parameters after pruning\n",
        "    macs, nparams = tp.utils.count_ops_and_params(model, input_sample)\n",
        "\n",
        "    print(f\"MACs: {macs}, #Params: {nparams}\")\n",
        "    print(f\"Parameter reduction: {original_nparams - nparams}\")\n",
        "\n",
        "    # Free up memory\n",
        "    del input_sample, output_sample, preds\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return model, macs, nparams"
      ],
      "metadata": {
        "id": "Y9Tgh_b86IqE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model, macs, nparams = prune_model(mobilenet_v2,'channel_pruning_Taylor_importance', pruning_ratios, input, output, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d87UelrA670D",
        "outputId": "d81ab517-6052-46e9-ca49-763178127efc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruning block 0 with initial ratio: 0.96\n",
            "Pruning block 1 with initial ratio: 0.96\n",
            "Pruning block 2 with initial ratio: 0.96\n",
            "Pruning block 3 with initial ratio: 0.96\n",
            "Pruning block 4 with initial ratio: 0.96\n",
            "Pruning block 5 with initial ratio: 0.96\n",
            "Pruning block 6 with initial ratio: 0.96\n",
            "Pruning block 7 with initial ratio: 0.96\n",
            "Pruning block 8 with initial ratio: 0.96\n",
            "Pruning block 9 with initial ratio: 0.96\n",
            "Pruning block 10 with initial ratio: 0.96\n",
            "Pruning block 11 with initial ratio: 0.96\n",
            "Pruning block 12 with initial ratio: 0.96\n",
            "Pruning block 13 with initial ratio: 0.96\n",
            "Pruning block 14 with initial ratio: 0.97\n",
            "Pruning block 15 with initial ratio: 0.97\n",
            "Pruning block 16 with initial ratio: 0.99\n",
            "Pruning block 17 with initial ratio: 0.97\n",
            "MACs: 4341561.0, #Params: 51873\n",
            "Parameter reduction: 2174561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model"
      ],
      "metadata": {
        "id": "Ze_NHm-37VAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f38a04af-3ec0-4790-c405-347f32d6c45d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV2(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=3, bias=False)\n",
              "          (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(3, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=5, bias=False)\n",
              "          (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(5, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(5, 5, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=5, bias=False)\n",
              "          (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(5, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=7, bias=False)\n",
              "          (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(7, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=7, bias=False)\n",
              "          (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(7, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(7, 7, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=7, bias=False)\n",
              "          (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(7, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15, bias=False)\n",
              "          (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15, bias=False)\n",
              "          (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15, bias=False)\n",
              "          (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=15, bias=False)\n",
              "          (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(15, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=23, bias=False)\n",
              "          (1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(23, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=23, bias=False)\n",
              "          (1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(23, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(23, 23, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=23, bias=False)\n",
              "          (1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(23, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=28, bias=False)\n",
              "          (1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(28, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (16): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=28, bias=False)\n",
              "          (1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(28, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (17): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
              "          (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(9, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (18): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 38, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Linear(in_features=38, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}